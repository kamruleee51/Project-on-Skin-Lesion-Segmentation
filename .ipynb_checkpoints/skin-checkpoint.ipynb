{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the required Packages and library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Image Path for loading the Images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CurrentDirectory=os.getcwd()\n",
    "imagePath = CurrentDirectory+'/Data/TrainImage2/'\n",
    "maskPath = CurrentDirectory+'/Data/TrainGT2/'\n",
    "predictedMask=CurrentDirectory+'/mask/'\n",
    "overlay=CurrentDirectory+'/overlay/'\n",
    "height, width = 128, 128\n",
    "SEED=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the data vector of the Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = [x for x in sorted(os.listdir(imagePath)) if x[-4:] == '.png']\n",
    "\n",
    "x_data = np.empty((len(all_images), height, width), dtype='float32')\n",
    "\n",
    "for i, name in enumerate(all_images):\n",
    "    im = cv2.imread(imagePath + name, 0).astype(\"int16\").astype('float32')\n",
    "    im = cv2.resize(im, dsize=(width, height), interpolation=cv2.INTER_LANCZOS4)\n",
    "    im = (im - np.min(im)) / (np.max(im) - np.min(im))\n",
    "    x_data[i] = im\n",
    "\n",
    "y_data = np.empty((len(all_images), height, width), dtype='float32')\n",
    "for i, name in enumerate(all_images):\n",
    "    im = cv2.imread(maskPath + name, 0).astype('float32')/255.\n",
    "    im = cv2.resize(im, dsize=(width, height), interpolation=cv2.INTER_NEAREST)\n",
    "    y_data[i] = im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (8,4))\n",
    "ax[0].imshow(x_data[10], cmap='gray')\n",
    "ax[1].imshow(y_data[10], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data[:,:,:,np.newaxis]\n",
    "y_data = y_data[:,:,:,np.newaxis]\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size = 0.5)\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "shape=x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=x_train.shape[1:])\n",
    "\n",
    "conv_1 = Conv2D(filters=8, kernel_size=(3,3), activation='relu', padding='same')(input_layer)\n",
    "maxpool = MaxPool2D(strides=(2,2))(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same')(maxpool)\n",
    "maxpool = MaxPool2D(strides=(2,2))(conv_2)\n",
    "\n",
    "conv_3 = Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(maxpool)\n",
    "maxpool = MaxPool2D(strides=(2,2))(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(maxpool)\n",
    "maxpool = MaxPool2D(strides=(2,2))(conv_4)\n",
    "\n",
    "conv_5 = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='same')(maxpool)\n",
    "\n",
    "deconv = concatenate([UpSampling2D(size=(2,2))(conv_5), conv_4], axis=-1)\n",
    "deconv = Conv2D(filters=32, kernel_size=(2,2), activation='relu', padding='same')(deconv)\n",
    "\n",
    "deconv = concatenate([UpSampling2D(size=(2,2))(deconv), conv_3], axis=-1)\n",
    "deconv = Conv2D(filters=24, kernel_size=(2,2), activation='relu', padding='same')(deconv)\n",
    "\n",
    "deconv = concatenate([UpSampling2D(size=(2,2))(deconv), conv_2], axis=-1)\n",
    "deconv = Conv2D(filters=16, kernel_size=(2,2), activation='relu', padding='same')(deconv)\n",
    "\n",
    "deconv = concatenate([UpSampling2D(size=(2,2))(deconv), conv_1], axis=-1)\n",
    "deconv = Conv2D(filters=16, kernel_size=(2,2), activation='relu', padding='same')(deconv)\n",
    "\n",
    "deconv = Conv2D(filters=64, kernel_size=(1,1), activation='relu')(deconv)\n",
    "\n",
    "deconv= Dropout(0.3)(deconv)\n",
    "\n",
    "\n",
    "output_layer = Conv2D(filters=1, kernel_size=(1,1), activation='sigmoid')(deconv)\n",
    "                                                         \n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_generator(x_train, y_train, batch_size):\n",
    "    data_generator = ImageDataGenerator(\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            rotation_range=20,\n",
    "#             rescale=10,\n",
    "            zoom_range=0.1).flow(x_train, x_train, batch_size, seed=SEED)\n",
    "    mask_generator = ImageDataGenerator(\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            rotation_range=20,\n",
    "#             rescale=10,\n",
    "            zoom_range=0.1).flow(y_train, y_train, batch_size, seed=SEED)\n",
    "    while True:\n",
    "        x_batch, _ = data_generator.next()\n",
    "        y_batch, _ = mask_generator.next()\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, mask_batch = next(my_generator(x_train, y_train, 8))\n",
    "fix, ax = plt.subplots(8,2, figsize=(8,20))\n",
    "for i in range(8):\n",
    "    ax[i,0].imshow(image_batch[i,:,:,0])\n",
    "    ax[i,1].imshow(mask_batch[i,:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(2e-4), loss='binary_crossentropy', metrics=[dice_coef])\n",
    "weight_saver = ModelCheckpoint('SavedModel.h5', monitor='val_dice_coef',save_best_only=True, save_weights_only=True)\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.8 ** x, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(my_generator(x_train, y_train, 16),\n",
    "                           steps_per_epoch = 2,\n",
    "                           validation_data = (x_val, y_val),\n",
    "                           epochs=2, verbose=1,\n",
    "                           callbacks = [weight_saver, annealer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('SavedModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.grid('on')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['dice_coef'])\n",
    "plt.plot(hist.history['val_dice_coef'])\n",
    "plt.title('Model dice_coef')\n",
    "plt.ylabel('dice_coef')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "y_hat = model.predict(x_val)\n",
    "fig, ax = plt.subplots(1,3,figsize=(12,6))\n",
    "ax[0].imshow(x_val[0,:,:,0], cmap='gray')\n",
    "ax[1].imshow(y_val[0,:,:,0], cmap='gray')\n",
    "ax[2].imshow(y_hat[0,:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel=disk(5)\n",
    "for i in range(len(x_val)):\n",
    "    prediction=model.predict(x_val[i].reshape(1,height, width, 1))\n",
    "    image=prediction.reshape(height,width)\n",
    "#     print(image.dtype)\n",
    "    image *= 255 # or any coefficient\n",
    "    image = image.astype(np.uint8)\n",
    "    ret3,image = cv2.threshold(image,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    image=cv2.erode(image,kernel,iterations = 1)\n",
    "#     print(image.dtype)\n",
    "#     print(image)\n",
    "    labelImage=label(image)\n",
    "    regions=regionprops(labelImage)\n",
    "    Area=[]\n",
    "    for region in range(len(regions)):\n",
    "        maxThreshold=regions[region].area\n",
    "        Area.append(maxThreshold)\n",
    "#     print(Area)\n",
    "    X= sorted( [(x,i) for (i,x) in enumerate(Area)], reverse=True )[:2]\n",
    "    index=np.array(X)\n",
    "    V=index.T[1].tolist()\n",
    "#     print((V[0]+1))  \n",
    "    \n",
    "    R=image.copy()\n",
    "    L=image.copy()\n",
    "    \n",
    "    R[labelImage!=(V[1]+1)]=0\n",
    "    L[labelImage!=(V[0]+1)]=0\n",
    "    \n",
    "    final=R+L\n",
    "    final=cv2.dilate(final,kernel,iterations = 1)\n",
    "    \n",
    "    seg_img = cv2.merge((final,final,final))\n",
    "    seg_img = seg_img.astype(np.uint8)\n",
    "    seg_img[:,:,0]=0\n",
    "    seg_img[:,:,2]=0\n",
    "   \n",
    "    \n",
    "    temp_originalImage=((x_val[i].reshape(1,height, width, 1)).reshape(height, width))\n",
    "    \n",
    "    seg_img = cv2.merge((final,final,final))\n",
    "    seg_img = seg_img.astype(np.uint8)\n",
    "    seg_img[:,:,0]=0\n",
    "    seg_img[:,:,2]=0\n",
    "    \n",
    "#     print(originalImage.dtype)\n",
    "#     overlay = cv2.addWeighted(final,0.3,originalImage,0.7,0)\n",
    "#     temp_originalImage[final!=0] = 255\n",
    "\n",
    "    outName=predictedMask+'mask_'+str(i)+'.png'\n",
    "    cv2.imwrite(  outName , final )\n",
    "#     cv2.imwrite(  outName_Masked , temp.astype(np.uint8) )\n",
    "\n",
    "#     plt.figure()\n",
    "    plt.imshow(temp_originalImage, 'gray', interpolation='none')\n",
    "    plt.imshow(seg_img, 'jet', interpolation='none', alpha=0.3)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    saveName=overlay+'OverLay_'+str(i)+'.png'\n",
    "    plt.savefig(saveName, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

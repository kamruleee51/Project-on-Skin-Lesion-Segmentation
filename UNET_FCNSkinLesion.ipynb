{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamru\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import cv2\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.losses import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "n=224\n",
    "from __future__ import print_function\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "from skimage.measure import label, regionprops\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.initializers import Constant\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.morphology import disk\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FCN8(nClasses, input_height, input_width):\n",
    "\n",
    "    #-----------------------------------------Define Input and Create VGG Layers---------------------------------------\n",
    "    img_input = Input(shape=(input_height, input_width, 3))\n",
    "    vgg = VGG16( weights='imagenet', include_top=False, input_tensor=img_input)\n",
    "\n",
    "\n",
    "    #----------------------------------------FCN8 for the segmentation-------------------------------------------------\n",
    "    vgg_out = Conv2D(filters=4096, kernel_size=(7, 7), padding=\"same\", activation=\"relu\", name=\"fc6\")(vgg.output)\n",
    "#     o = Dropout(rate=0.5)(o)\n",
    "    \n",
    "    vgg_out_conv_1 = Conv2D(filters=4096, kernel_size=(1, 1), padding=\"same\", activation=\"relu\", name=\"fc7\")(vgg_out)\n",
    "#     o = Dropout(rate=0.5)(o)\n",
    "\n",
    "    vgg_out_conv_2 = Conv2D(filters=nClasses, kernel_size=(1, 1), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "               name=\"score_fr\")(vgg_out_conv_1)\n",
    "\n",
    "    vgg_out_convTR = Conv2DTranspose(filters= nClasses,\n",
    "                                     kernel_size=(2, 2), \n",
    "                                     strides=(2, 2), \n",
    "                                     padding=\"valid\", \n",
    "                                     activation=None,\n",
    "#                                      kernel_initializer=Constant(bilinear_upsample_weights(2, nClasses)),\n",
    "                                     name=\"score2\")(vgg_out_conv_1)\n",
    "\n",
    "    # Conv to be applied on Pool4\n",
    "    skip_con1 = Conv2D(nClasses, kernel_size=(1, 1), padding=\"same\", activation=None, kernel_initializer=\"he_normal\",\n",
    "                       name=\"score_pool4\")(vgg.get_layer(\"block4_pool\").output)\n",
    "    Skip_1 = add(inputs=[skip_con1, vgg_out_convTR])\n",
    "\n",
    "    Skip_temp = Conv2DTranspose(nClasses, \n",
    "                                kernel_size=(2, 2), \n",
    "                                strides=(2, 2), \n",
    "                                padding=\"valid\", \n",
    "                                activation=None,\n",
    "#                                 kernel_initializer=Constant(bilinear_upsample_weights(2, nClasses)),\n",
    "                                name=\"score4\")(Skip_1)\n",
    "\n",
    "    ###\n",
    "    skip_con2 = Conv2D(nClasses, kernel_size=(1, 1), padding=\"same\", activation=None, kernel_initializer=\"he_normal\",\n",
    "                       name=\"score_pool3\")(vgg.get_layer(\"block3_pool\").output)\n",
    "    Skip_2 = add(inputs=[skip_con2, Skip_temp])\n",
    "\n",
    "    #####\n",
    "    fINALlAYER = Conv2DTranspose(nClasses, \n",
    "                                 kernel_size=(8, 8), \n",
    "                                 strides=(8, 8),\n",
    "                                 padding=\"valid\", \n",
    "                                 activation='relu', \n",
    "#                                  kernel_initializer=bilinear_upsample_weights(8, nClasses),\n",
    "                                 name=\"upsampling\")(Skip_2)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    vgg_Base = vgg\n",
    "    \n",
    "    deconv_1 = UpSampling2D((2, 2))(vgg_Base.output)\n",
    "    deconv_1 = concatenate([vgg_Base.get_layer(name=\"block4_pool\").output, deconv_1], axis=-1)\n",
    "    deconv_1 = Conv2D(512, (3, 3), padding=\"same\")(deconv_1)\n",
    "    deconv_1 = BatchNormalization()(deconv_1)\n",
    "\n",
    "    deconv_2 = UpSampling2D((2, 2))(deconv_1)\n",
    "    deconv_2 = concatenate([vgg_Base.get_layer(name=\"block3_pool\").output, deconv_2], axis=-1)\n",
    "    deconv_2 = Conv2D(256, (3, 3), padding=\"same\")(deconv_2)\n",
    "    deconv_2 = BatchNormalization()(deconv_2)\n",
    "\n",
    "    deconv_3 = UpSampling2D((2, 2))(deconv_2)\n",
    "    deconv_3 = concatenate([vgg_Base.get_layer(name=\"block2_pool\").output, deconv_3], axis=-1)\n",
    "    deconv_3 = Conv2D(128, (3, 3), padding=\"same\")(deconv_3)\n",
    "    deconv_3 = BatchNormalization()(deconv_3)\n",
    "\n",
    "    deconv_4 = UpSampling2D((2, 2))(deconv_3)\n",
    "    deconv_4 = concatenate([vgg_Base.get_layer( name=\"block1_pool\").output, deconv_4], axis=-1)\n",
    "    deconv_4 = Conv2D(64, (3, 3), padding=\"same\")(deconv_4)\n",
    "    deconv_4 = BatchNormalization()(deconv_4)\n",
    "\n",
    "    deconv_5 = UpSampling2D((2, 2))(deconv_4)\n",
    "    deconv_5 = Conv2D(64, (3, 3), padding=\"same\")(deconv_5)\n",
    "    deconv_5 = BatchNormalization()(deconv_5)\n",
    "\n",
    "    deconv_6 = Conv2D(nClasses, (1, 1), padding=\"same\")(deconv_5)\n",
    "    deconv_6 = BatchNormalization()(deconv_6)\n",
    "    deconv_6 = Activation(\"relu\")(deconv_6)\n",
    "\n",
    "#     deconv_7 = Reshape((-1, nClasses))(deconv_6)\n",
    "#     deconv_7 = Activation(\"softmax\")(deconv_7)\n",
    "\n",
    "#     conv10 = Conv2D(1, 1, activation = 'sigmoid')(deconv_6)\n",
    "\n",
    "    \n",
    "    deco6=Average()([deconv_6, fINALlAYER])\n",
    "    \n",
    "    conv = Conv2D(1, 1, activation = 'sigmoid')(deco6)\n",
    "    \n",
    "    modelUNET = Model(input = img_input, output = conv)\n",
    "\n",
    "\n",
    "#     for layer in modelUNET.layers[:26]:\n",
    "#         layer.trainable = False \n",
    "\n",
    "\n",
    "    return modelUNET\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjustData(img, mask):\n",
    "# #     img = preprocess_input(img)\n",
    "#     img2= np.zeros_like(img)\n",
    "#     for i in range(len(img[:,1,1,1])):\n",
    "#         image=img[i,:,:,:]\n",
    "# #         print(image.dtype)\n",
    "        \n",
    "#         im=preprocess_input(image)\n",
    "#         grayVGG=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "# #         grayVGG=grayVGG.astype(np.uint8)\n",
    "        \n",
    "#         b,g,r=cv2.split(image)\n",
    "        \n",
    "#         gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "# #         print(b.shape)\n",
    "# #         print(b.dtype)\n",
    "        \n",
    "# #         print(gray.shape)\n",
    "# #         print(gray.dtype)\n",
    "        \n",
    "        \n",
    "# #         print(grayVGG.shape)\n",
    "# #         print(grayVGG.dtype)\n",
    "        \n",
    "#         sytheticImage=cv2.merge((b,grayVGG,gray))\n",
    "        \n",
    "# #         print(sytheticImage.shape)\n",
    "       \n",
    "        \n",
    "#         sytheticImage = sytheticImage/sytheticImage.max()\n",
    "        \n",
    "        \n",
    "#         img2 [i,:,:,:]=sytheticImage\n",
    "        \n",
    "    img = preprocess_input(img)\n",
    "    img = img/img.max() \n",
    "    mask = mask/mask.max() \n",
    "\n",
    "    return (img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainGenerator(batch_size, train_path, image_folder, mask_folder, aug_dict, image_color_mode = \"rgb\",\n",
    "                    mask_color_mode = \"grayscale\", image_save_prefix  = \"image\", mask_save_prefix  = \"mask\",\n",
    "                    save_to_dir = None, target_size = (n,n), seed = 1):\n",
    "    \n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    \n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = 'rgb',\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        seed = seed)\n",
    "\n",
    "    \n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed)\n",
    "\n",
    "    \n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    \n",
    "    for (img,mask) in train_generator:\n",
    "        img,mask = adjustData(img,mask)\n",
    "        yield (img,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ValGenerator(batch_size, val_path, image_folder, mask_folder, target_size = (n,n), seed = 1):\n",
    "    \n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    \n",
    "    image_datagen = ImageDataGenerator()\n",
    "    mask_datagen = ImageDataGenerator()\n",
    "    \n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = 'rgb',\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        seed = seed)\n",
    "\n",
    "    \n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        seed = seed)\n",
    "\n",
    "    \n",
    "    val_generator = zip(image_generator, mask_generator)\n",
    "    \n",
    "    for (img,mask) in val_generator:\n",
    "        img,mask = adjustData(img,mask)\n",
    "        yield (img,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, K.sigmoid(y_pred)) + dice_loss(y_true, K.sigmoid(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamru\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:96: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 512)  0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 1024) 0           block4_pool[0][0]                \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 14, 14, 512)  2048        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 512)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 768)  0           block3_pool[0][0]                \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 256)  1769728     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 256)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 56, 56, 384)  0           block2_pool[0][0]                \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 56, 128)  442496      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 56, 56, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 112, 112, 192 0           block1_pool[0][0]                \n",
      "                                                                 up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 112, 112, 64) 110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 112, 112, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc6 (Conv2D)                    (None, 7, 7, 4096)   102764544   block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fc7 (Conv2D)                    (None, 7, 7, 4096)   16781312    fc6[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 224, 224, 64) 36928       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "score_pool4 (Conv2D)            (None, 14, 14, 2)    1026        block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "score2 (Conv2DTranspose)        (None, 14, 14, 2)    32770       fc7[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 224, 224, 64) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 14, 14, 2)    0           score_pool4[0][0]                \n",
      "                                                                 score2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 224, 224, 2)  130         batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "score_pool3 (Conv2D)            (None, 28, 28, 2)    514         block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "score4 (Conv2DTranspose)        (None, 28, 28, 2)    18          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 224, 224, 2)  8           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 28, 28, 2)    0           score_pool3[0][0]                \n",
      "                                                                 score4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 2)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "upsampling (Conv2DTranspose)    (None, 224, 224, 2)  258         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 224, 224, 2)  0           activation_1[0][0]               \n",
      "                                                                 upsampling[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 224, 224, 1)  3           average_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 141,378,279\n",
      "Trainable params: 141,376,227\n",
      "Non-trainable params: 2,052\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data_gen_args = dict(rotation_range=10,\n",
    "                    width_shift_range=0.1,\n",
    "                    height_shift_range=0.1,\n",
    "                    shear_range=0.1,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "CurrentDirectory=os.getcwd()\n",
    "\n",
    "TrainGen= trainGenerator(batch_size=10, train_path=CurrentDirectory+'/Data', image_folder='TrainImage2', mask_folder='TrainGT2',\n",
    "                       aug_dict=data_gen_args, image_color_mode = \"grayscale\", mask_color_mode = \"grayscale\",\n",
    "                       image_save_prefix  = \"image\", mask_save_prefix  = \"mask\", save_to_dir = CurrentDirectory+'/Aug/',\n",
    "                       target_size = (n,n), seed = 1)\n",
    "\n",
    "\n",
    "TestGen= ValGenerator(batch_size=10, val_path=CurrentDirectory+'/Data', image_folder='TestImage2', \n",
    "                      mask_folder='TestGT2', target_size = (n,n), seed = 1)\n",
    "\n",
    "model = FCN8(2, n, n)\n",
    "\n",
    "model.compile(optimizer = 'adadelta',\n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "plot_model(model, show_shapes=True, to_file='model_unet.png')\n",
    "model.summary()\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('modelSaved.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "# history=model.fit_generator(TrainGen, \n",
    "#                             steps_per_epoch=200, \n",
    "#                             epochs=200, \n",
    "#                             verbose=1, \n",
    "#                             validation_data= TestGen, \n",
    "#                             validation_steps=60, \n",
    "#                             callbacks=[model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Plot training & validation accuracy values\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.grid('on')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # Plot training & validation loss values\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.grid('on')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice(im1, im2, empty_score=1.0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the Dice coefficient, a measure of set similarity.\n",
    "    Parameters\n",
    "    ----------\n",
    "    im1 : array-like, bool\n",
    "        Any array of arbitrary size. If not boolean, will be converted.\n",
    "    im2 : array-like, bool\n",
    "        Any other array of identical size. If not boolean, will be converted.\n",
    "    Returns\n",
    "    -------\n",
    "    dice : float\n",
    "        Dice coefficient as a float on range [0,1].\n",
    "        Maximum similarity = 1\n",
    "        No similarity = 0\n",
    "        Both are empty (sum eq to zero) = empty_score\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The order of inputs for `dice` is irrelevant. The result will be\n",
    "    identical if `im1` and `im2` are switched.\n",
    "    \"\"\"\n",
    "    \n",
    "    im1 = np.asarray(im1).astype(np.bool)\n",
    "    im2 = np.asarray(im2).astype(np.bool)\n",
    "\n",
    "    if im1.shape != im2.shape:\n",
    "        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n",
    "\n",
    "    im_sum = im1.sum() + im2.sum()\n",
    "    if im_sum == 0:\n",
    "        return empty_score\n",
    "\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "\n",
    "    return 2. * intersection.sum() / im_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard(im1, im2, empty_score=1.0):\n",
    "    \"\"\"\n",
    "    Computes the Dice coefficient, a measure of set similarity.\n",
    "    Parameters\n",
    "    ----------\n",
    "    im1 : array-like, bool\n",
    "        Any array of arbitrary size. If not boolean, will be converted.\n",
    "    im2 : array-like, bool\n",
    "        Any other array of identical size. If not boolean, will be converted.\n",
    "    Returns\n",
    "    -------\n",
    "    dice : float\n",
    "        Dice coefficient as a float on range [0,1].\n",
    "        Maximum similarity = 1\n",
    "        No similarity = 0\n",
    "        Both are empty (sum eq to zero) = empty_score\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The order of inputs for `dice` is irrelevant. The result will be\n",
    "    identical if `im1` and `im2` are switched.\n",
    "    \"\"\"\n",
    "    im1 = np.asarray(im1).astype(np.bool)\n",
    "    im2 = np.asarray(im2).astype(np.bool)\n",
    "\n",
    "    if im1.shape != im2.shape:\n",
    "        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n",
    "\n",
    "    im_sum = im1.sum() + im2.sum()\n",
    "    if im_sum == 0:\n",
    "        return empty_score\n",
    "\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "    union = np.logical_or(im1, im2)\n",
    "\n",
    "    return intersection.sum() / float(union.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dicee=[]\n",
    "JI=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamru\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:96: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "C:\\Users\\kamru\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\kamru\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "testGene = CurrentDirectory+'/ISIC-2017_Validation_Data (2)/'\n",
    "GTPath= CurrentDirectory+'/ISIC-2017_Validation_Part1_GroundTruth/'\n",
    "GT = glob.glob(GTPath+\"*.png\")\n",
    "GT.sort()\n",
    "\n",
    "CurrentDirectory=os.getcwd()\n",
    "MaskSavePath= CurrentDirectory+'/Mask/'\n",
    "target_size = (n,n)\n",
    "imagePath = glob.glob(testGene+\"*.jpg\")\n",
    "imagePath.sort()\n",
    "# print(imagePath)\n",
    "kernel=disk(5)\n",
    "model = FCN8(2, n, n)\n",
    "model.load_weights(\"modelSaved.hdf5\")\n",
    "\n",
    "for imageName,gg in zip(imagePath,GT):\n",
    "    img = cv2.imread(imageName,-1)\n",
    "    sss=img.copy()\n",
    "    filename, file_extension = os.path.splitext(imageName)  \n",
    "    img = trans.resize(img,target_size)\n",
    "    path0=MaskSavePath+filename[-12:]+'___'+file_extension\n",
    "    sss = cv2.resize(sss, (n, n)) \n",
    "    cv2.imwrite(path0,sss)\n",
    "    \n",
    "    \n",
    "#     img = preprocess_input(img)\n",
    "    img=np.expand_dims(img, axis=0)\n",
    "    Pr=model.predict(img,verbose=0)\n",
    "    Pr=Pr.reshape(n,n)\n",
    "    one=255*Pr/Pr.max()\n",
    "#     Pr[Pr<0.5]=0\n",
    "#     one[one!=0]=255\n",
    "#     print(Pr.shape)   \n",
    "#     mx=one.max()\n",
    "#     mn=one.min()\n",
    "#     th=(mx+mn)/2\n",
    "#     one[one<th]=0\n",
    "#     ret2,th2 = cv2.threshold(one,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    path=MaskSavePath+filename[-12:]+file_extension\n",
    "#     th=(one.max())/7\n",
    "# #     print(one.min())\n",
    "#     T=one.min()+1e-6\n",
    "#     one[one<th]=0\n",
    "#     one[one>=th]=255\n",
    "    one=one.astype('uint8')\n",
    "    cv2.imwrite(path,one)\n",
    "    the,_=cv2.threshold(one,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "#     print(the)\n",
    "    T=0.8*(one.max())\n",
    "    one[one<T]=0\n",
    "    one[one>=T]=255\n",
    "    \n",
    "    labelImage=label(one)\n",
    "    regions=regionprops(labelImage)\n",
    "    Area=[]\n",
    "    for region in range(len(regions)):\n",
    "        maxThreshold=regions[region].area,\n",
    "        Area.append(maxThreshold)\n",
    "        \n",
    "#     print(Area)\n",
    "\n",
    "    X= sorted( [(x,i) for (i,x) in enumerate(Area)], reverse=True )[:2]\n",
    "    \n",
    "    index=np.array(X)\n",
    "    \n",
    "    V=index.T[1].tolist()\n",
    "    \n",
    "#     print(V[0])\n",
    "#     print((V[0]+1))\n",
    "\n",
    "    R=one.copy(),\n",
    "    one[labelImage!=(V[0]+1)]=0,\n",
    "\n",
    "#     \"    final=cv2.dilate(final,kernel,iterations = 1)\\n\",\n",
    "#     \"    \\n\",\n",
    "#     \"    seg_img = cv2.merge((final,final,final))\\n\",\n",
    "#     \"    seg_img = seg_img.astype(np.uint8)\\n\",\n",
    "#     \"    seg_img[:,:,0]=0\\n\",\n",
    "#     \"    seg_img[:,:,2]=0\\n\",\n",
    "#     one = cv2.erode(one,kernel,iterations = 1)\n",
    "#     one[one!=0]=255\n",
    "\n",
    "    path2=MaskSavePath+filename[-12:]+'_'+file_extension\n",
    "    cv2.imwrite(path2,one)\n",
    "    \n",
    "     \n",
    "    imGT=cv2.imread(gg,-1)\n",
    "\n",
    "    imGT = cv2.resize(imGT, (n, n)) \n",
    "\n",
    "    tttt=cv2.merge((one,one,one))\n",
    "    tttt[:,:,0]=0\n",
    "    tttt[:,:,2]=0\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(imGT, 'gray', interpolation='none')\n",
    "    plt.imshow(tttt, 'jet', interpolation='none', alpha=0.3)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    path3=MaskSavePath+filename[-12:]+'__'+file_extension\n",
    "    plt.savefig(path3, bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (5,50)\n",
    "    fontScale              = 1\n",
    "    fontColor              = (0,0,255)\n",
    "    lineType               = 2\n",
    "    \n",
    "    dd=dice(imGT,one)\n",
    "    ji=jaccard(imGT,one)\n",
    "    dicee.append(dd)\n",
    "    JI.append(ji)\n",
    "    \n",
    "    imageee=cv2.imread(path3,-1)\n",
    "    cv2.putText(imageee,str(dd), \n",
    "    bottomLeftCornerOfText, \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    lineType)\n",
    "    path4=MaskSavePath+filename[-12:]+'_____'+file_extension\n",
    "    cv2.imwrite(path4,imageee)\n",
    "    \n",
    "print(\"DSC = %0.4f (+/-%0.04f)\" % (np.mean(dicee)*100, np.std(dicee)*100))\n",
    "# print(\"Intersection over Union = %0.4f (+/-%0.04f)\" % (np.mean(IU)*100, np.std(IU)*100))\n",
    "# print(\"Sensitivity = %0.4f (+/-%0.04f)\" % (np.mean(Sensitivity)*100, np.std(Sensitivity)*100))\n",
    "# print(\"Specificity = %0.4f (+/-%0.04f)\" % (np.mean(Specificity)*100, np.std(Specificity)*100))\n",
    "# print(\"Accuracy = %0.8f (+/-%0.04f)\" % (np.mean(Accuracy)*100, np.std(Accuracy)*100))\n",
    "# print(\"Balanced Accuracy = %0.4f (+/-%0.04f)\" % (np.mean(BalancedAccuracy)*100, np.std(BalancedAccuracy)*100))\n",
    "# print(\"AUC = %0.4f (+/-%0.04f)\" % (np.mean(ROC_AUC)*100, np.std(ROC_AUC)*100))\n",
    "print(\"JI = %0.4f (+/-%0.04f)\" % (np.mean(JI)*100, np.std(JI)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CurrentDirectory=os.getcwd()\n",
    "# PR=CurrentDirectory+'/Mask/'\n",
    "# GTPath= CurrentDirectory+'/ISIC-2017_Validation_Part1_GroundTruth/'\n",
    "# output_path=CurrentDirectory+'/GTPR/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR = glob.glob(PR+\"*.jpg\")\n",
    "# OR.sort()\n",
    "# print(len(OR))\n",
    "# GT = glob.glob(GTPath+\"*.png\")\n",
    "# GT.sort()\n",
    "# print(len(GT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def compute_iou(y_pred, y_true):\n",
    "#     # ytrue, ypred is a flatten vector\n",
    "#     y_pred = y_pred.flatten()\n",
    "#     y_true = y_true.flatten()\n",
    "#     cm= confusion_matrix(y_true, y_pred, labels=[0, 1]) # cm means confusion Matrix\n",
    "#      # compute mean iou\n",
    "#     intersection = np.diag(cm)\n",
    "#     ground_truth_set = cm.sum(axis=1)\n",
    "#     predicted_set = cm.sum(axis=0)\n",
    "#     union = ground_truth_set + predicted_set - intersection\n",
    "#     IoU = intersection / union.astype(np.float32)\n",
    "#     return np.mean(IoU), cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def dice(im1, im2, empty_score=1.0):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Computes the Dice coefficient, a measure of set similarity.\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     im1 : array-like, bool\n",
    "#         Any array of arbitrary size. If not boolean, will be converted.\n",
    "#     im2 : array-like, bool\n",
    "#         Any other array of identical size. If not boolean, will be converted.\n",
    "#     Returns\n",
    "#     -------\n",
    "#     dice : float\n",
    "#         Dice coefficient as a float on range [0,1].\n",
    "#         Maximum similarity = 1\n",
    "#         No similarity = 0\n",
    "#         Both are empty (sum eq to zero) = empty_score\n",
    "        \n",
    "#     Notes\n",
    "#     -----\n",
    "#     The order of inputs for `dice` is irrelevant. The result will be\n",
    "#     identical if `im1` and `im2` are switched.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     im1 = np.asarray(im1).astype(np.bool)\n",
    "#     im2 = np.asarray(im2).astype(np.bool)\n",
    "\n",
    "#     if im1.shape != im2.shape:\n",
    "#         raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n",
    "\n",
    "#     im_sum = im1.sum() + im2.sum()\n",
    "#     if im_sum == 0:\n",
    "#         return empty_score\n",
    "\n",
    "#     # Compute Dice coefficient\n",
    "#     intersection = np.logical_and(im1, im2)\n",
    "\n",
    "#     return 2. * intersection.sum() / im_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def jaccard(im1, im2, empty_score=1.0):\n",
    "#     \"\"\"\n",
    "#     Computes the Dice coefficient, a measure of set similarity.\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     im1 : array-like, bool\n",
    "#         Any array of arbitrary size. If not boolean, will be converted.\n",
    "#     im2 : array-like, bool\n",
    "#         Any other array of identical size. If not boolean, will be converted.\n",
    "#     Returns\n",
    "#     -------\n",
    "#     dice : float\n",
    "#         Dice coefficient as a float on range [0,1].\n",
    "#         Maximum similarity = 1\n",
    "#         No similarity = 0\n",
    "#         Both are empty (sum eq to zero) = empty_score\n",
    "        \n",
    "#     Notes\n",
    "#     -----\n",
    "#     The order of inputs for `dice` is irrelevant. The result will be\n",
    "#     identical if `im1` and `im2` are switched.\n",
    "#     \"\"\"\n",
    "#     im1 = np.asarray(im1).astype(np.bool)\n",
    "#     im2 = np.asarray(im2).astype(np.bool)\n",
    "\n",
    "#     if im1.shape != im2.shape:\n",
    "#         raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n",
    "\n",
    "#     im_sum = im1.sum() + im2.sum()\n",
    "#     if im_sum == 0:\n",
    "#         return empty_score\n",
    "\n",
    "#     # Compute Dice coefficient\n",
    "#     intersection = np.logical_and(im1, im2)\n",
    "#     union = np.logical_or(im1, im2)\n",
    "\n",
    "#     return intersection.sum() / float(union.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IU=[]\n",
    "Sensitivity=[]\n",
    "Specificity=[]\n",
    "Accuracy=[]\n",
    "BalancedAccuracy=[]\n",
    "ROC_AUC=[]\n",
    "dicee=[]\n",
    "JI=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total Number of images should be same as the total number of segmented Mask\n",
    "# import math\n",
    "# assert len(OR) == len(GT) \n",
    "\n",
    "# # kernel=disk(10)\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(10,10))\n",
    "\n",
    "# i=5000\n",
    "# # Checking that every image has their corresponding segmented mask.\n",
    "\n",
    "# for im , seg in zip(OR,GT):\n",
    "    \n",
    "#     Image, _ = os.path.splitext(im)\n",
    "#     GT,_     = os.path.splitext(seg)\n",
    "    \n",
    "#     assert(Image[-4:]   ==  GT[-4:]  )\n",
    "    \n",
    "#     pred=cv2.imread(im,0)\n",
    "\n",
    "#     predicted = cv2.resize(pred, (n, n)) \n",
    "    \n",
    "# #     predicted = cv2.erode(predicted,kernel,iterations = 1)\n",
    "# #     predicted = cv2.morphologyEx(predicted, cv2.MORPH_OPEN, kernel)\n",
    "#     imGT=cv2.imread(seg,0)\n",
    "    \n",
    "#     imGT[imGT!=0]=255\n",
    "\n",
    "#     imGT = cv2.resize(imGT, (n, n)) \n",
    "\n",
    "#     tttt=cv2.merge((predicted,predicted,predicted))\n",
    "#     tttt[:,:,0]=0\n",
    "#     tttt[:,:,2]=0\n",
    "\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.imshow(imGT, 'gray', interpolation='none')\n",
    "#     plt.imshow(tttt, 'jet', interpolation='none', alpha=0.3)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     saveName=output_path+'OverLay_'+str(i)+'.png'\n",
    "#     plt.savefig(saveName, bbox_inches='tight')\n",
    "#     plt.clf()\n",
    "#     i=i+1\n",
    "    \n",
    "#     dd=dice(predicted,imGT)\n",
    "#     dicee.append(dd)\n",
    "    \n",
    "#     Jscrore=jaccard(predicted,imGT)\n",
    "#     JI.append(Jscrore)\n",
    "\n",
    "#     ret,im = cv2.threshold(imGT,250,255,cv2.THRESH_BINARY)\n",
    "#     im=im/im.max()\n",
    "#     Predicted=np.array(im).ravel()\n",
    "\n",
    "#     ret,GT = cv2.threshold(pred,250,255,cv2.THRESH_BINARY)\n",
    "#     GT=GT/GT.max()\n",
    "#     GroundTruth=np.array(GT).ravel()\n",
    "    \n",
    "#     if math.isnan(np.sum(GroundTruth))!=True:\n",
    "    \n",
    "#         IoU, ConfusionMatrix=compute_iou(Predicted,GroundTruth)\n",
    "\n",
    "\n",
    "#         IU.append(IoU)\n",
    "\n",
    "#         TN = ConfusionMatrix[0][0]\n",
    "#         FP = ConfusionMatrix[0][1]\n",
    "#         FN = ConfusionMatrix[1][0]\n",
    "#         TP = ConfusionMatrix[1][1]\n",
    "\n",
    "#         temp_Sensitivity=(TP/(TP+FN))\n",
    "#         Sensitivity.append(temp_Sensitivity)\n",
    "\n",
    "#         temp_Specificity=(TN/(FP+TN))\n",
    "#         Specificity.append(temp_Specificity)\n",
    "\n",
    "#         temp_Accuracy=((TP+TN)/(TP+TN+FP+FN))\n",
    "#         Accuracy.append(temp_Accuracy)\n",
    "\n",
    "#         temp_BalancedAccuracy=(temp_Sensitivity+temp_Specificity)/2\n",
    "#         BalancedAccuracy.append(temp_BalancedAccuracy)\n",
    "\n",
    "#         fpr, tpr, thresholds =roc_curve(GroundTruth, Predicted)\n",
    "#         roc_auc = auc(fpr, tpr)\n",
    "#         ROC_AUC.append(roc_auc)\n",
    "\n",
    "\n",
    "#         font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#         bottomLeftCornerOfText = (5,50)\n",
    "#         fontScale              = 1\n",
    "#         fontColor              = (0,0,255)\n",
    "#         lineType               = 2\n",
    "\n",
    "#         img=cv2.imread(saveName,-1)\n",
    "#         cv2.putText(img,str(dd), \n",
    "#             bottomLeftCornerOfText, \n",
    "#             font, \n",
    "#             fontScale,\n",
    "#             fontColor,\n",
    "#             lineType)\n",
    "#         saveName2=output_path+'OverLay_'+str(i)+'.jpg'\n",
    "#         cv2.imwrite(saveName2,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"DSC = %0.4f (+/-%0.04f)\" % (np.mean(dicee)*100, np.std(dicee)*100))\n",
    "# print(\"Intersection over Union = %0.4f (+/-%0.04f)\" % (np.mean(IU)*100, np.std(IU)*100))\n",
    "# print(\"Sensitivity = %0.4f (+/-%0.04f)\" % (np.mean(Sensitivity)*100, np.std(Sensitivity)*100))\n",
    "# print(\"Specificity = %0.4f (+/-%0.04f)\" % (np.mean(Specificity)*100, np.std(Specificity)*100))\n",
    "# print(\"Accuracy = %0.8f (+/-%0.04f)\" % (np.mean(Accuracy)*100, np.std(Accuracy)*100))\n",
    "# print(\"Balanced Accuracy = %0.4f (+/-%0.04f)\" % (np.mean(BalancedAccuracy)*100, np.std(BalancedAccuracy)*100))\n",
    "# print(\"AUC = %0.4f (+/-%0.04f)\" % (np.mean(ROC_AUC)*100, np.std(ROC_AUC)*100))\n",
    "# print(\"JI = %0.4f (+/-%0.04f)\" % (np.mean(JI)*100, np.std(JI)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DSC = 83.0834 (+/-18.2871)\n",
    "# Intersection over Union = 81.9845 (+/-15.4320)\n",
    "# Sensitivity = 91.0542 (+/-14.3432)\n",
    "# Specificity = 93.1068 (+/-14.2170)\n",
    "# Accuracy = 93.01185352 (+/-10.0934)\n",
    "# Balanced Accuracy = 92.0805 (+/-9.1937)\n",
    "# AUC = 92.0805 (+/-9.1937)\n",
    "# JI = 74.2650 (+/-20.8103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DSC = 81.0715 (+/-15.6450)\n",
    "# Intersection over Union = 76.5855 (+/-14.6711)\n",
    "# Sensitivity = 73.8209 (+/-18.7216)\n",
    "# Specificity = 96.1745 (+/-11.2689)\n",
    "# Accuracy = 90.07974243 (+/-10.6796)\n",
    "# Balanced Accuracy = 84.9977 (+/-9.3809)\n",
    "# AUC = 84.9977 (+/-9.3809)\n",
    "# JI = 70.4928 (+/-17.9819)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

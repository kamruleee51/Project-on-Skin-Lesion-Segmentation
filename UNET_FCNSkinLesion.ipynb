{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamru\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import cv2\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.losses import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "n=224\n",
    "from __future__ import print_function\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "from skimage.measure import label, regionprops\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.initializers import Constant\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.morphology import disk\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FCN8(nClasses, input_height, input_width):\n",
    "\n",
    "    #-----------------------------------------Define Input and Create VGG Layers---------------------------------------\n",
    "    img_input = Input(shape=(input_height, input_width, 3))\n",
    "    vgg = VGG16( weights='imagenet', include_top=False, input_tensor=img_input)\n",
    "\n",
    "\n",
    "    #----------------------------------------FCN8 for the segmentation-------------------------------------------------\n",
    "    vgg_out = Conv2D(filters=4096, kernel_size=(7, 7), padding=\"same\", activation=\"relu\", name=\"fc6\")(vgg.output)\n",
    "#     o = Dropout(rate=0.5)(o)\n",
    "    \n",
    "    vgg_out_conv_1 = Conv2D(filters=4096, kernel_size=(1, 1), padding=\"same\", activation=\"relu\", name=\"fc7\")(vgg_out)\n",
    "#     o = Dropout(rate=0.5)(o)\n",
    "\n",
    "    vgg_out_conv_2 = Conv2D(filters=nClasses, kernel_size=(1, 1), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "               name=\"score_fr\")(vgg_out_conv_1)\n",
    "\n",
    "    vgg_out_convTR = Conv2DTranspose(filters= nClasses,\n",
    "                                     kernel_size=(2, 2), \n",
    "                                     strides=(2, 2), \n",
    "                                     padding=\"valid\", \n",
    "                                     activation=None,\n",
    "#                                      kernel_initializer=Constant(bilinear_upsample_weights(2, nClasses)),\n",
    "                                     name=\"score2\")(vgg_out_conv_1)\n",
    "\n",
    "    # Conv to be applied on Pool4\n",
    "    skip_con1 = Conv2D(nClasses, kernel_size=(1, 1), padding=\"same\", activation=None, kernel_initializer=\"he_normal\",\n",
    "                       name=\"score_pool4\")(vgg.get_layer(\"block4_pool\").output)\n",
    "    Skip_1 = add(inputs=[skip_con1, vgg_out_convTR])\n",
    "\n",
    "    Skip_temp = Conv2DTranspose(nClasses, \n",
    "                                kernel_size=(2, 2), \n",
    "                                strides=(2, 2), \n",
    "                                padding=\"valid\", \n",
    "                                activation=None,\n",
    "#                                 kernel_initializer=Constant(bilinear_upsample_weights(2, nClasses)),\n",
    "                                name=\"score4\")(Skip_1)\n",
    "\n",
    "    ###\n",
    "    skip_con2 = Conv2D(nClasses, kernel_size=(1, 1), padding=\"same\", activation=None, kernel_initializer=\"he_normal\",\n",
    "                       name=\"score_pool3\")(vgg.get_layer(\"block3_pool\").output)\n",
    "    Skip_2 = add(inputs=[skip_con2, Skip_temp])\n",
    "\n",
    "    #####\n",
    "    fINALlAYER = Conv2DTranspose(nClasses, \n",
    "                                 kernel_size=(8, 8), \n",
    "                                 strides=(8, 8),\n",
    "                                 padding=\"valid\", \n",
    "                                 activation='relu', \n",
    "#                                  kernel_initializer=bilinear_upsample_weights(8, nClasses),\n",
    "                                 name=\"upsampling\")(Skip_2)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    vgg_Base = vgg\n",
    "    \n",
    "    deconv_1 = UpSampling2D((2, 2))(vgg_Base.output)\n",
    "    deconv_1 = concatenate([vgg_Base.get_layer(name=\"block4_pool\").output, deconv_1], axis=-1)\n",
    "    deconv_1 = Conv2D(512, (3, 3), padding=\"same\")(deconv_1)\n",
    "    deconv_1 = BatchNormalization()(deconv_1)\n",
    "\n",
    "    deconv_2 = UpSampling2D((2, 2))(deconv_1)\n",
    "    deconv_2 = concatenate([vgg_Base.get_layer(name=\"block3_pool\").output, deconv_2], axis=-1)\n",
    "    deconv_2 = Conv2D(256, (3, 3), padding=\"same\")(deconv_2)\n",
    "    deconv_2 = BatchNormalization()(deconv_2)\n",
    "\n",
    "    deconv_3 = UpSampling2D((2, 2))(deconv_2)\n",
    "    deconv_3 = concatenate([vgg_Base.get_layer(name=\"block2_pool\").output, deconv_3], axis=-1)\n",
    "    deconv_3 = Conv2D(128, (3, 3), padding=\"same\")(deconv_3)\n",
    "    deconv_3 = BatchNormalization()(deconv_3)\n",
    "\n",
    "    deconv_4 = UpSampling2D((2, 2))(deconv_3)\n",
    "    deconv_4 = concatenate([vgg_Base.get_layer( name=\"block1_pool\").output, deconv_4], axis=-1)\n",
    "    deconv_4 = Conv2D(64, (3, 3), padding=\"same\")(deconv_4)\n",
    "    deconv_4 = BatchNormalization()(deconv_4)\n",
    "\n",
    "    deconv_5 = UpSampling2D((2, 2))(deconv_4)\n",
    "    deconv_5 = Conv2D(64, (3, 3), padding=\"same\")(deconv_5)\n",
    "    deconv_5 = BatchNormalization()(deconv_5)\n",
    "\n",
    "    deconv_6 = Conv2D(nClasses, (1, 1), padding=\"same\")(deconv_5)\n",
    "    deconv_6 = BatchNormalization()(deconv_6)\n",
    "    deconv_6 = Activation(\"relu\")(deconv_6)\n",
    "\n",
    "#     deconv_7 = Reshape((-1, nClasses))(deconv_6)\n",
    "#     deconv_7 = Activation(\"softmax\")(deconv_7)\n",
    "\n",
    "#     conv10 = Conv2D(1, 1, activation = 'sigmoid')(deconv_6)\n",
    "\n",
    "    \n",
    "    deco6=Average()([deconv_6, fINALlAYER])\n",
    "    \n",
    "    conv = Conv2D(1, 1, activation = 'sigmoid')(deco6)\n",
    "    \n",
    "    modelUNET = Model(input = img_input, output = conv)\n",
    "\n",
    "\n",
    "    for layer in modelUNET.layers[:26]:\n",
    "        layer.trainable = False \n",
    "\n",
    "\n",
    "    return modelUNET\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjustData(img, mask):\n",
    "# #     img = preprocess_input(img)\n",
    "#     img2= np.zeros_like(img)\n",
    "#     for i in range(len(img[:,1,1,1])):\n",
    "#         image=img[i,:,:,:]\n",
    "# #         print(image.dtype)\n",
    "        \n",
    "#         im=preprocess_input(image)\n",
    "#         grayVGG=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "# #         grayVGG=grayVGG.astype(np.uint8)\n",
    "        \n",
    "#         b,g,r=cv2.split(image)\n",
    "        \n",
    "#         gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "# #         print(b.shape)\n",
    "# #         print(b.dtype)\n",
    "        \n",
    "# #         print(gray.shape)\n",
    "# #         print(gray.dtype)\n",
    "        \n",
    "        \n",
    "# #         print(grayVGG.shape)\n",
    "# #         print(grayVGG.dtype)\n",
    "        \n",
    "#         sytheticImage=cv2.merge((b,grayVGG,gray))\n",
    "        \n",
    "# #         print(sytheticImage.shape)\n",
    "       \n",
    "        \n",
    "#         sytheticImage = sytheticImage/sytheticImage.max()\n",
    "        \n",
    "        \n",
    "#         img2 [i,:,:,:]=sytheticImage\n",
    "        \n",
    "    img = preprocess_input(img)\n",
    "    img = img/img.max() \n",
    "    mask = mask/mask.max() \n",
    "\n",
    "    return (img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainGenerator(batch_size, train_path, image_folder, mask_folder, aug_dict, image_color_mode = \"rgb\",\n",
    "                    mask_color_mode = \"grayscale\", image_save_prefix  = \"image\", mask_save_prefix  = \"mask\",\n",
    "                    save_to_dir = None, target_size = (n,n), seed = 1):\n",
    "    \n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    \n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = 'rgb',\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        seed = seed)\n",
    "\n",
    "    \n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed)\n",
    "\n",
    "    \n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    \n",
    "    for (img,mask) in train_generator:\n",
    "        img,mask = adjustData(img,mask)\n",
    "        yield (img,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ValGenerator(batch_size, val_path, image_folder, mask_folder, target_size = (n,n), seed = 1):\n",
    "    \n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    \n",
    "    image_datagen = ImageDataGenerator()\n",
    "    mask_datagen = ImageDataGenerator()\n",
    "    \n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = 'rgb',\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        seed = seed)\n",
    "\n",
    "    \n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        seed = seed)\n",
    "\n",
    "    \n",
    "    val_generator = zip(image_generator, mask_generator)\n",
    "    \n",
    "    for (img,mask) in val_generator:\n",
    "        img,mask = adjustData(img,mask)\n",
    "        yield (img,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, K.sigmoid(y_pred)) + dice_loss(y_true, K.sigmoid(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamru\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:96: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 512)  0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 1024) 0           block4_pool[0][0]                \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 14, 14, 512)  2048        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 512)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 768)  0           block3_pool[0][0]                \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 256)  1769728     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 256)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 56, 56, 384)  0           block2_pool[0][0]                \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 56, 128)  442496      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 56, 56, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 112, 112, 192 0           block1_pool[0][0]                \n",
      "                                                                 up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 112, 112, 64) 110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 112, 112, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc6 (Conv2D)                    (None, 7, 7, 4096)   102764544   block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fc7 (Conv2D)                    (None, 7, 7, 4096)   16781312    fc6[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 224, 224, 64) 36928       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "score_pool4 (Conv2D)            (None, 14, 14, 2)    1026        block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "score2 (Conv2DTranspose)        (None, 14, 14, 2)    32770       fc7[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 224, 224, 64) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 14, 14, 2)    0           score_pool4[0][0]                \n",
      "                                                                 score2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 224, 224, 2)  130         batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "score_pool3 (Conv2D)            (None, 28, 28, 2)    514         block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "score4 (Conv2DTranspose)        (None, 28, 28, 2)    18          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 224, 224, 2)  8           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 28, 28, 2)    0           score_pool3[0][0]                \n",
      "                                                                 score4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 2)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "upsampling (Conv2DTranspose)    (None, 224, 224, 2)  258         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 224, 224, 2)  0           activation_1[0][0]               \n",
      "                                                                 upsampling[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 224, 224, 1)  3           average_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 141,378,279\n",
      "Trainable params: 120,171,683\n",
      "Non-trainable params: 21,206,596\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "Found 150 images belonging to 1 classes.\n",
      "Found 1998 images belonging to 1 classes.\n",
      "Found 150 images belonging to 1 classes.\n",
      "Found 1998 images belonging to 1 classes.\n",
      "400/400 [==============================] - 610s 2s/step - loss: 0.4059 - dice_coef: 0.6591 - val_loss: 0.2837 - val_dice_coef: 0.7324\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.28368, saving model to modelSaved.hdf5\n",
      "Epoch 2/60\n",
      "400/400 [==============================] - 593s 1s/step - loss: 0.2283 - dice_coef: 0.7818 - val_loss: 0.2747 - val_dice_coef: 0.7382\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.28368 to 0.27467, saving model to modelSaved.hdf5\n",
      "Epoch 3/60\n",
      "400/400 [==============================] - 596s 1s/step - loss: 0.2082 - dice_coef: 0.8000 - val_loss: 0.2534 - val_dice_coef: 0.7575\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.27467 to 0.25340, saving model to modelSaved.hdf5\n",
      "Epoch 4/60\n",
      "400/400 [==============================] - 605s 2s/step - loss: 0.1989 - dice_coef: 0.8080 - val_loss: 0.4191 - val_dice_coef: 0.5817\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25340\n",
      "Epoch 5/60\n",
      "400/400 [==============================] - 603s 2s/step - loss: 0.1851 - dice_coef: 0.8213 - val_loss: 0.2610 - val_dice_coef: 0.7462\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25340\n",
      "Epoch 6/60\n",
      "400/400 [==============================] - 575s 1s/step - loss: 0.1775 - dice_coef: 0.8285 - val_loss: 0.2683 - val_dice_coef: 0.7363\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25340\n",
      "Epoch 7/60\n",
      "400/400 [==============================] - 568s 1s/step - loss: 0.1787 - dice_coef: 0.8265 - val_loss: 0.2505 - val_dice_coef: 0.7543\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.25340 to 0.25053, saving model to modelSaved.hdf5\n",
      "Epoch 8/60\n",
      "400/400 [==============================] - 614s 2s/step - loss: 0.1662 - dice_coef: 0.8389 - val_loss: 0.2477 - val_dice_coef: 0.7583\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.25053 to 0.24768, saving model to modelSaved.hdf5\n",
      "Epoch 9/60\n",
      "400/400 [==============================] - 624s 2s/step - loss: 0.1662 - dice_coef: 0.8386 - val_loss: 0.2356 - val_dice_coef: 0.7706\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.24768 to 0.23558, saving model to modelSaved.hdf5\n",
      "Epoch 10/60\n",
      "400/400 [==============================] - 607s 2s/step - loss: 0.1579 - dice_coef: 0.8462 - val_loss: 0.2827 - val_dice_coef: 0.7187\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.23558\n",
      "Epoch 11/60\n",
      "400/400 [==============================] - 604s 2s/step - loss: 0.1598 - dice_coef: 0.8442 - val_loss: 0.2187 - val_dice_coef: 0.7886\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.23558 to 0.21872, saving model to modelSaved.hdf5\n",
      "Epoch 12/60\n",
      "400/400 [==============================] - 606s 2s/step - loss: 0.1550 - dice_coef: 0.8489 - val_loss: 0.2339 - val_dice_coef: 0.7713\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.21872\n",
      "Epoch 13/60\n",
      "400/400 [==============================] - 611s 2s/step - loss: 0.1565 - dice_coef: 0.8473 - val_loss: 0.2180 - val_dice_coef: 0.7891\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.21872 to 0.21803, saving model to modelSaved.hdf5\n",
      "Epoch 14/60\n",
      "400/400 [==============================] - 610s 2s/step - loss: 0.1524 - dice_coef: 0.8512 - val_loss: 0.2542 - val_dice_coef: 0.7485\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.21803\n",
      "Epoch 15/60\n",
      "400/400 [==============================] - 611s 2s/step - loss: 0.1553 - dice_coef: 0.8481 - val_loss: 0.2145 - val_dice_coef: 0.7888\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.21803 to 0.21450, saving model to modelSaved.hdf5\n",
      "Epoch 16/60\n",
      " 22/400 [>.............................] - ETA: 5:47 - loss: 0.2887 - dice_coef: 0.7138"
     ]
    }
   ],
   "source": [
    "data_gen_args = dict(rotation_range=10,\n",
    "                    width_shift_range=0.1,\n",
    "                    height_shift_range=0.1,\n",
    "                    shear_range=0.1,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "CurrentDirectory=os.getcwd()\n",
    "\n",
    "TrainGen= trainGenerator(batch_size=5, train_path=CurrentDirectory+'/Data', image_folder='TrainImage2', mask_folder='TrainGT2',\n",
    "                       aug_dict=data_gen_args, image_color_mode = \"grayscale\", mask_color_mode = \"grayscale\",\n",
    "                       image_save_prefix  = \"image\", mask_save_prefix  = \"mask\", save_to_dir = CurrentDirectory+'/Aug/',\n",
    "                       target_size = (n,n), seed = 1)\n",
    "\n",
    "\n",
    "TestGen= ValGenerator(batch_size=5, val_path=CurrentDirectory+'/Data', image_folder='TestImage3', \n",
    "                      mask_folder='TestGT3', target_size = (n,n), seed = 1)\n",
    "\n",
    "model = FCN8(2, n, n)\n",
    "\n",
    "model.compile(optimizer = 'adadelta',\n",
    "              loss = dice_loss, \n",
    "              metrics = [dice_coef])\n",
    "\n",
    "plot_model(model, show_shapes=True, to_file='model_unet.png')\n",
    "model.summary()\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('modelSaved.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "history=model.fit_generator(TrainGen, \n",
    "                            steps_per_epoch=400, \n",
    "                            epochs=60, \n",
    "                            verbose=1, \n",
    "                            validation_data= TestGen, \n",
    "                            validation_steps=30, \n",
    "                            callbacks=[model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['dice_coef'])\n",
    "plt.plot(history.history['val_dice_coef'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.grid('on')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice(im1, im2, empty_score=1.0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the Dice coefficient, a measure of set similarity.\n",
    "    Parameters\n",
    "    ----------\n",
    "    im1 : array-like, bool\n",
    "        Any array of arbitrary size. If not boolean, will be converted.\n",
    "    im2 : array-like, bool\n",
    "        Any other array of identical size. If not boolean, will be converted.\n",
    "    Returns\n",
    "    -------\n",
    "    dice : float\n",
    "        Dice coefficient as a float on range [0,1].\n",
    "        Maximum similarity = 1\n",
    "        No similarity = 0\n",
    "        Both are empty (sum eq to zero) = empty_score\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The order of inputs for `dice` is irrelevant. The result will be\n",
    "    identical if `im1` and `im2` are switched.\n",
    "    \"\"\"\n",
    "    \n",
    "    im1 = np.asarray(im1).astype(np.bool)\n",
    "    im2 = np.asarray(im2).astype(np.bool)\n",
    "\n",
    "    if im1.shape != im2.shape:\n",
    "        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n",
    "\n",
    "    im_sum = im1.sum() + im2.sum()\n",
    "    if im_sum == 0:\n",
    "        return empty_score\n",
    "\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "\n",
    "    return 2. * intersection.sum() / im_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard(im1, im2, empty_score=1.0):\n",
    "    \"\"\"\n",
    "    Computes the Dice coefficient, a measure of set similarity.\n",
    "    Parameters\n",
    "    ----------\n",
    "    im1 : array-like, bool\n",
    "        Any array of arbitrary size. If not boolean, will be converted.\n",
    "    im2 : array-like, bool\n",
    "        Any other array of identical size. If not boolean, will be converted.\n",
    "    Returns\n",
    "    -------\n",
    "    dice : float\n",
    "        Dice coefficient as a float on range [0,1].\n",
    "        Maximum similarity = 1\n",
    "        No similarity = 0\n",
    "        Both are empty (sum eq to zero) = empty_score\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The order of inputs for `dice` is irrelevant. The result will be\n",
    "    identical if `im1` and `im2` are switched.\n",
    "    \"\"\"\n",
    "    im1 = np.asarray(im1).astype(np.bool)\n",
    "    im2 = np.asarray(im2).astype(np.bool)\n",
    "\n",
    "    if im1.shape != im2.shape:\n",
    "        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n",
    "\n",
    "    im_sum = im1.sum() + im2.sum()\n",
    "    if im_sum == 0:\n",
    "        return empty_score\n",
    "\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "    union = np.logical_or(im1, im2)\n",
    "\n",
    "    return intersection.sum() / float(union.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dicee=[]\n",
    "JI=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testGene = CurrentDirectory+'/ISIC-2017_Validation_Data (2)/'\n",
    "imagePath = glob.glob(testGene+\"*.jpg\")\n",
    "imagePath.sort()\n",
    "\n",
    "GTPath= CurrentDirectory+'/ISIC-2017_Validation_Part1_GroundTruth/'\n",
    "GT = glob.glob(GTPath+\"*.png\")\n",
    "GT.sort()\n",
    "\n",
    "\n",
    "MaskSavePath= CurrentDirectory+'/Mask/'\n",
    "\n",
    "target_size = (n,n)\n",
    "\n",
    "kernel=disk(7)\n",
    "kernel2=disk(8)\n",
    "\n",
    "model = FCN8(2, n, n)\n",
    "model.load_weights(\"modelSaved.hdf5\")\n",
    "\n",
    "for imageName, gg in zip(imagePath,GT):\n",
    "    img = cv2.imread(imageName,-1)\n",
    "    sss=img.copy()\n",
    "    \n",
    "    filename, file_extension = os.path.splitext(imageName)  \n",
    "    img = trans.resize(img,target_size)\n",
    "    \n",
    "    path0=MaskSavePath+filename[-12:]+'_org'+file_extension\n",
    "    sss = cv2.resize(sss, (n, n)) \n",
    "    cv2.imwrite(path0,sss)\n",
    "    \n",
    "    \n",
    "#     img = preprocess_input(img)\n",
    "    img=np.expand_dims(img, axis=0)\n",
    "    Pr=model.predict(img,verbose=0)\n",
    "    Pr=Pr.reshape(n,n)\n",
    "    path=MaskSavePath+filename[-12:]+'_pred'+file_extension\n",
    "    cv2.imwrite(path,255*Pr)\n",
    "    \n",
    "    \n",
    "    one=255*Pr\n",
    "\n",
    "\n",
    "    one=one.astype('uint8')\n",
    "\n",
    "    the,one=cv2.threshold(one,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "#     one=cv2.erode(one,kernel,iterations = 1)\n",
    "    \n",
    "#     labelImage=label(one)\n",
    "#     regions=regionprops(labelImage)\n",
    "#     Area=[]\n",
    "#     for region in range(len(regions)):\n",
    "#         maxThreshold=regions[region].area,\n",
    "#         Area.append(maxThreshold)\n",
    "#     X= sorted( [(x,i) for (i,x) in enumerate(Area)], reverse=True )[:2]\n",
    "    \n",
    "#     index=np.array(X)\n",
    "#     V=index.T[1].tolist()\n",
    "# #     one[labelImage!=(V[0]+1)]=0,\n",
    "\n",
    "    \n",
    "#     one=cv2.dilate(one,kernel2,iterations = 1)\n",
    "    \n",
    "    path2=MaskSavePath+filename[-12:]+'_mask'+file_extension\n",
    "    cv2.imwrite(path2,one)\n",
    "    \n",
    "    \n",
    "    imGT=cv2.imread(gg,-1)\n",
    "    imGT = cv2.resize(imGT, (n, n)) \n",
    "    tttt=cv2.merge((one,one,one))\n",
    "    tttt[:,:,0]=0\n",
    "    tttt[:,:,2]=0\n",
    "\n",
    "\n",
    "#     plt.figure()\n",
    "    plt.imshow(imGT, 'gray', interpolation='none')\n",
    "    plt.imshow(tttt, 'jet', interpolation='none', alpha=0.3)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    path3=MaskSavePath+filename[-12:]+'_overlay'+file_extension\n",
    "    plt.savefig(path3, bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    \n",
    "    \n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (5,50)\n",
    "    fontScale              = 1\n",
    "    fontColor              = (0,0,255)\n",
    "    lineType               = 2\n",
    "    \n",
    "    dd=dice(imGT,one)\n",
    "    ji=jaccard(imGT,one)\n",
    "    dicee.append(dd)\n",
    "    JI.append(ji)\n",
    "    \n",
    "    imageee=cv2.imread(path3,-1)\n",
    "    cv2.putText(imageee,str(dd), \n",
    "    bottomLeftCornerOfText, \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    lineType)\n",
    "    path4=MaskSavePath+filename[-12:]+'_dice'+file_extension\n",
    "    cv2.imwrite(path4,imageee)\n",
    "    \n",
    "print(\"DSC = %0.4f (+/-%0.04f)\" % (np.mean(dicee)*100, np.std(dicee)*100))\n",
    "# print(\"Intersection over Union = %0.4f (+/-%0.04f)\" % (np.mean(IU)*100, np.std(IU)*100))\n",
    "# print(\"Sensitivity = %0.4f (+/-%0.04f)\" % (np.mean(Sensitivity)*100, np.std(Sensitivity)*100))\n",
    "# print(\"Specificity = %0.4f (+/-%0.04f)\" % (np.mean(Specificity)*100, np.std(Specificity)*100))\n",
    "# print(\"Accuracy = %0.8f (+/-%0.04f)\" % (np.mean(Accuracy)*100, np.std(Accuracy)*100))\n",
    "# print(\"Balanced Accuracy = %0.4f (+/-%0.04f)\" % (np.mean(BalancedAccuracy)*100, np.std(BalancedAccuracy)*100))\n",
    "# print(\"AUC = %0.4f (+/-%0.04f)\" % (np.mean(ROC_AUC)*100, np.std(ROC_AUC)*100))\n",
    "print(\"JI = %0.4f (+/-%0.04f)\" % (np.mean(JI)*100, np.std(JI)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
